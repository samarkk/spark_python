{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = 'D:/spark231hdp27'\n",
    "os.environ['SPARK_HOME']= spark_home\n",
    "os.environ['PYLIB']=os.environ['SPARK_HOME']+'/python/lib'\n",
    "sys.path.insert(0,os.environ['PYLIB']+'/py4j-0.10.6-src.zip')\n",
    "sys.path.insert(1,os.environ['PYLIB']+'/pyspark.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('RecommenderModel') \\\n",
    ".config('spark.warehouse.dir','/apps/hive/warehouse') \\\n",
    ".config('spark.driver.memory', '6G') \\\n",
    ".config('spark.sql.shuffle.partitions', 4) \\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having set the driver and driver options we should have spark representing spark session \n",
    "# available straight away\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a look at the loaded raw user and artist data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1000002 1 55',\n",
       " '1000002 1000006 33',\n",
       " '1000002 1000007 8',\n",
       " '1000002 1000009 144',\n",
       " '1000002 1000010 314']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the user and artist played data into a rdd\n",
    "userArtistFileLoc = \"D:/ufdata/audioscrobbler/user_artist_data.txt\"\n",
    "rawUserArtistData = sc.textFile(userArtistFileLoc)\n",
    "print(\"Take a look at the loaded raw user and artist data\")\n",
    "rawUserArtistData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of user and artist integer ids\n",
    "from pyspark.ml.recommendation import *\n",
    "userArtistDF = rawUserArtistData.map(lambda line: line.split(' ')) \\\n",
    ".map(lambda x: (int(x[0]), int(x[1]))).toDF([\"user\", \"artist\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------+\n",
      "|min(user)|max(user)|min(artist)|max(artist)|\n",
      "+---------+---------+-----------+-----------+\n",
      "|       90|  2443548|          1|   10794401|\n",
      "+---------+---------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets look at the min and max user and artist ids to verify that we are within the range for integer values\n",
    "from pyspark.sql.functions import *\n",
    "userArtistDF.agg(min(col(\"user\")), max(col(\"user\")), min(col(\"artist\")), max(col(\"artist\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take a look at the artist data which we will use to take care of aliases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1134999\\t06Crazy Life',\n",
       " '6821360\\tPang Nakarin',\n",
       " '10113088\\tTerfel, Bartoli- Mozart: Don',\n",
       " '10151459\\tThe Flaming Sidebur',\n",
       " '6826647\\tBodenstandig 3000']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have the artist data which is ids and artist name\n",
    "artistFileLoc = \"D:/ufdata/audioscrobbler/artist_data.txt\"\n",
    "print(\"take a look at the artist data which we will use to take care of aliases\")\n",
    "rawArtistData = sc.textFile(artistFileLoc)\n",
    "rawArtistData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to weed out instances where the name is missing\n",
    "# use the line below to see such instances  \n",
    "# grep --color -P  '^\\d+\\s+$' artist_data.txt\n",
    "# grep --color -P -v '^\\d+' artist_data.txt | wc -l\n",
    "# grep --color -P -v '\\d+\\s+\\S+' artist_data.txt\n",
    "rawArtistData.map(lambda x: x.split('\\t')).filter(lambda x: len(x) < 2).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the artist data\n",
    "### Should have a  tuple and the first part should be numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10589651', 'q¬‹', ' [Tokyo Jihen]'],\n",
       " ['\\x07ú',\n",
       "  'F\\x05Ù\\x08\\x90\\x01â\\x05\\x12ýM\\x01qøöû)ô\\x13÷Bñ÷óÕð\\x81ópò;ôêóÍô®õ\\x19÷7ú\\x97û[ÿ>ÿ\\x8d\\x014\\x01à\\x02I\\x03\\x8f\\x05£\\x05\\x12\\x07\\x80\\x06\\xa0\\x05y\\x04Æ\\x02',\n",
       "  '\\x01\\x87'],\n",
       " ['10484061', 'Toshihiko Seki ', '5 (Sanzou)'],\n",
       " ['1153538', 'Donæt Stop', ' (Ballistic Bass remix)'],\n",
       " ['1161565',\n",
       "  'ýùürüÇú@\\x01ÍÿÝ\\x05^\\x06\\x8a\\x05Z\\x08W\\x02Q\\x05çûúüandù)øßù:ø;þ>ýÙ',\n",
       "  '\\x9a\\x08ì\\x0e\\x15\\x0c\\x85\\x05É\\x02u÷\\x9b÷.ñ,ô\\x86÷\\x83úÉ\\x02ý\\x02¾\\x05\\x9c\\x03³\\x06%\\x05E\\x0b;\\x0b\\xad\\x06º\\x06i÷,÷ÁîCïeø0ú¥\\x02\\x94\\x04<\\x01|\\x01U\\x03Z\\x02ï\\x0cÝ\\x0c±\\x0e\\x8d\\x0f\\x06\\x024\\x02#ô\\x89ómñ|']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawArtistData.map(lambda x: x.split('\\t')).filter(lambda x: len(x) > 2).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to tuples of length greater than one\n",
    "# then \n",
    "artistByID =  rawArtistData.map(lambda x: x.split('\\t')).filter(lambda x: len(x) > 1 and x[0].isdigit()) \\\n",
    ".map(lambda x: (int(x[0]), x[1])) \\\n",
    ".toDF(['id', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artistByID.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1848281"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistByID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawArtistFileLoc = \"D:/ufdata/audioscrobbler/artist_alias.txt\"\n",
    "rawArtistAlias = sc.textFile(rawArtistFileLoc)\n",
    "# grep --color -P  '^\\s+' artist_alias.txt  | wc -l\n",
    "# There are 2135 instances where we have an alias but no artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistAlias = dict(rawArtistAlias.map(lambda x: x.split('\\t')) \\\n",
    ".filter(lambda x: len(x) > 1).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of artist aliases\n",
    "len(artistAlias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcast the artis aliases\n",
    "bArtistAlias = sc.broadcast(artistAlias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in the training data  24296858\n"
     ]
    }
   ],
   "source": [
    "# use the artist aliases for creating the data for the model\n",
    "allData = rawUserArtistData.map (lambda line: line.split()) \\\n",
    ".map(lambda x: (int(x[0]), int(x[1]), int(x[2]))).map(lambda x: (x[0], \n",
    "    bArtistAlias.value.get(x[1], x[1]), x[2]) ) \\\n",
    ".toDF([\"user\", \"artist\", \"count\"]).cache()\n",
    "\n",
    "print(\"The number of records in the training data \" , allData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user: bigint, artist: bigint, count: bigint]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into training, cross validation\n",
    "trainData, cvData = allData.randomSplit((0.9, 0.1))\n",
    "trainData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "|user|artist|count|\n",
      "+----+------+-----+\n",
      "|1014|    26|    5|\n",
      "|1014|    28|    1|\n",
      "+----+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainData.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intitalize and fit the model\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "model = ALS(). \\\n",
    "setSeed(100). \\\n",
    "setImplicitPrefs(True). \\\n",
    "setRank(10). \\\n",
    "setRegParam(0.01). \\\n",
    "setAlpha(1.0). \\\n",
    "setMaxIter(5). \\\n",
    "setUserCol(\"user\"). \\\n",
    "setItemCol(\"artist\"). \\\n",
    "setRatingCol(\"count\"). \\\n",
    "setPredictionCol(\"prediction\") \\\n",
    ".fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(user=2093760, artist=1180, count=1), Row(user=2093760, artist=1255340, count=3), Row(user=2093760, artist=378, count=1), Row(user=2093760, artist=813, count=2), Row(user=2093760, artist=942, count=7)]\n"
     ]
    }
   ],
   "source": [
    "# see predictions for one user\n",
    "userID = 2093760\n",
    "existingArtistIDs = allData. \\\n",
    "filter(col('user') == userID).collect()\n",
    "print(existingArtistIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a method to find recommnedations for a specific user\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", True)\n",
    "def makeRecommendations(model, userID, howMany): \n",
    "    toRecommend = model.itemFactors. \\\n",
    "      selectExpr(\"id as artist\"). \\\n",
    "      withColumn(\"user\", lit(userID))\n",
    "    return model.transform(toRecommend). \\\n",
    "      select(\"artist\", \"prediction\"). \\\n",
    "      orderBy(desc(\"prediction\")). \\\n",
    "      limit(howMany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|user|artist|\n",
      "+----+------+\n",
      "|  90|  2814|\n",
      "| 120|  2814|\n",
      "| 340|  2814|\n",
      "| 350|  2814|\n",
      "| 770|  2814|\n",
      "|3290|  2814|\n",
      "|4370|  2814|\n",
      "|4620|  2814|\n",
      "|6060|  2814|\n",
      "|6390|  2814|\n",
      "|6760|  2814|\n",
      "|6850|  2814|\n",
      "|7010|  2814|\n",
      "|7130|  2814|\n",
      "|7290|  2814|\n",
      "|7340|  2814|\n",
      "|7400|  2814|\n",
      "|7510|  2814|\n",
      "|8500|  2814|\n",
      "|9660|  2814|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+----------+\n",
      "|   user|prediction|\n",
      "+-------+----------+\n",
      "|1070932| 1.5861955|\n",
      "|1071884| 1.3878194|\n",
      "|2023977| 1.3705223|\n",
      "|2157954| 1.3619362|\n",
      "|2062355|  1.354971|\n",
      "|1053071| 1.3533974|\n",
      "|2074380| 1.3504577|\n",
      "|2096140| 1.3492036|\n",
      "|2050441|   1.34675|\n",
      "|1064024| 1.3313961|\n",
      "|2232946| 1.3237069|\n",
      "|2071724| 1.3202682|\n",
      "|2208970| 1.3144891|\n",
      "|2281770| 1.3143957|\n",
      "|1066703| 1.3120208|\n",
      "|1066320|  1.310826|\n",
      "|1038950| 1.3050749|\n",
      "|1002794| 1.3005005|\n",
      "|1073469| 1.2960229|\n",
      "|2159806| 1.2947026|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets pick a user and check the predictions from the model for the user\n",
    "usersToRecommend = model.userFactors.selectExpr(\"id as user\").withColumn(\"artist\", lit(2814))\n",
    "usersToRecommend.show()\n",
    "model.transform(usersToRecommend). select(\"user\", \"prediction\"). \\\n",
    "orderBy(desc(\"prediction\")). \\\n",
    "limit(50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a look at the top ten recommendations we get from the model\n",
      "+-------+-----------+\n",
      "| artist| prediction|\n",
      "+-------+-----------+\n",
      "|1001819|0.028906701|\n",
      "|   2814|0.028640402|\n",
      "|1300642| 0.02856603|\n",
      "|   1811| 0.02854091|\n",
      "|   4605|0.028469205|\n",
      "|1004028|0.027916994|\n",
      "|    829|0.027856477|\n",
      "|1007614|  0.0278085|\n",
      "|1003249|0.027603466|\n",
      "|1037970|0.027352829|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topRecommendations = makeRecommendations(model, userID, 10)\n",
    "print(\"Take a look at the top ten recommendations we get from the model\")\n",
    "topRecommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524572\n",
      "147768\n",
      "147768\n",
      "1524572\n",
      "[Row(id=30, features=[-0.017250942066311836, 0.0034171261359006166, 0.0668657124042511, 0.09413359314203262, 0.07495716214179993, 0.08585923165082932, 0.04622870683670044, 0.0946611613035202, 0.021862678229808807, 0.1051500141620636])]\n",
      "[Row(id=90, features=[-0.4471117854118347, 0.43872979283332825, 1.248292326927185, 0.10280954092741013, -0.6020233631134033, 0.1628144085407257, -0.3863792419433594, 0.30432894825935364, 0.23583754897117615, 0.28717243671417236])]\n"
     ]
    }
   ],
   "source": [
    "# take a look at the two low rank matrices which are created\n",
    "# verify that the length of the item and user factors matches with distinct items(artists) and users respectively\n",
    "print(model.itemFactors.count())\n",
    "print(model.userFactors.count())\n",
    "print(trainData.select('user').distinct().count())\n",
    "print(trainData.select('artist').distinct().count())\n",
    "# the number of features for each matrix is given by the low rank k - 10 which we chose to create the model\n",
    "print(model.itemFactors.rdd.take(1))\n",
    "print(model.userFactors.rdd.take(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.userFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at the artist names that have been recommended\n",
      "[1001819, 2814, 1300642, 1811, 4605, 1004028, 829, 1007614, 1003249, 1037970]\n",
      "+-------+----------------+\n",
      "|     id|            name|\n",
      "+-------+----------------+\n",
      "|1004028|Notorious B.I.G.|\n",
      "|   2814|         50 Cent|\n",
      "|   4605|      Snoop Dogg|\n",
      "|    829|             Nas|\n",
      "|1007614|           Jay-Z|\n",
      "|1037970|      Kanye West|\n",
      "|   1811|         Dr. Dre|\n",
      "|1003249|        Ludacris|\n",
      "|1001819|            2Pac|\n",
      "|1300642|        The Game|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Look at the artist names that have been recommended\")\n",
    "recommendedArtistIDs = topRecommendations.select(\"artist\").rdd.map(lambda x: x[0]).collect()\n",
    "print(recommendedArtistIDs)\n",
    "recommendedArtists = artistByID.filter(col(\"id\").isin(recommendedArtistIDs))\n",
    "recommendedArtists.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.024357499554753304, 0.06565383076667786, 0.02214849554002285, -0.03441890701651573, -0.021594589576125145, 0.03341227397322655, 8.417641947744414e-05, 0.07064484804868698, 0.020837431773543358, 0.001333817606791854]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1001819, 0.028906702835987032),\n",
       " (2814, 0.028640404053358007),\n",
       " (1300642, 0.028566032990835166),\n",
       " (1811, 0.028540910459667335),\n",
       " (4605, 0.02846920442881667),\n",
       " (1004028, 0.027916993969010817),\n",
       " (829, 0.027856476078662328),\n",
       " (1007614, 0.027808499263035684),\n",
       " (1003249, 0.02760346476073714),\n",
       " (1037970, 0.02735282710719393)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the recommendation produced is a dot product of the user features and item features\n",
    "# first get the user features for the user id\n",
    "userFeatures = model.userFactors.filter(col(\"id\") == userID).select(\"features\").rdd.map(lambda x: x[0]).collect()[0]\n",
    "print(userFeatures)\n",
    "\n",
    "bUserFeatures = sc.broadcast(userFeatures)\n",
    "\n",
    "def calc_dotp(item_feats):\n",
    "    import builtins\n",
    "    return builtins.sum([x[0] * x[1] for x in zip(item_feats, bUserFeatures.value)])\n",
    "\n",
    "model.itemFactors.rdd.map(lambda x: (x[0], x[1])).map(lambda x: (x[0], calc_dotp(x[1]))).sortBy(lambda x: -x[1]).take(10)\n",
    "# we can see this is exactly the same as the top recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BinaryClassificationMetrics.areaUnderROC is not used here since there are really lots of\n",
    "###  small AUC problems, and it would be inefficient, when a direct computation is available\n",
    "\n",
    "### For carrying out the direct computations:\n",
    "### Use the model to get the positive predictions for the user\n",
    "\n",
    "### Create a set of \"negative\" products for each user. These are randomly chosen\n",
    "### from among all of the other artists, excluding those that are \"positive\" for the user.\n",
    "\n",
    "### Find the predicted scores for the negative dataset from the model\n",
    "\n",
    "### Join positive and negative predictions and compute individual area under the curve\n",
    "### as proportion of instances where positive prediction is greater than negative prediction\n",
    "\n",
    "### Find the mean of the indvidual auc scores to get the mean auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ==================================================================================\n",
    "###  Indvidual computations first to be canned into a method that we use for model tuning\n",
    "### ==================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model transform to get predictions\n",
    "positivePredictions = model.transform(cvData.select('user', 'artist')).withColumnRenamed('prediction', 'positivePrediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1014, {1016355, 1052005, 2885, 1020070, 1001607, 1011017, 1216424, 1004431, 1015697, 1097203, 1198804, 1004437, 1005877, 1005015, 9991320, 153, 10161277}, 17), (1000025, {1, 1000329, 1000333, 1236878, 1000340, 1001380, 813, 1001910, 1018807, 1001530, 1002427, 1003069, 1000639, 1004226, 1000656, 1235281, 3292, 1000674, 1000930, 1004515, 5477, 1004521, 1259, 4468, 1000056, 1000317}, 26)]\n"
     ]
    }
   ],
   "source": [
    "# negative data - to get as many random artists not listened to as number of artists listened to\n",
    "# get the distinct artists listened to by each user and the number\n",
    "negativeData = cvData.select('user', 'artist').rdd.map(lambda x: (x[0],x[1])).groupByKey() \\\n",
    ".map(lambda x: (x[0], set(x[1]))).map(lambda x: (x[0], x[1], len(x[1])))\n",
    "print(negativeData.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a broadcast variable for all artist ids to help in the flatmap that follow\n",
    "allArtistIds = allData.select('artist').distinct().rdd.map(lambda x: x[0]).collect()\n",
    "bAllArtistIds = sc.broadcast(allArtistIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1631028"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the length of artist ids\n",
    "len(bAllArtistIds.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a method to use in the flatmap to get user, artist pairs which for a user\n",
    "# are different from the artists he/she has listened to\n",
    "def negativePairs(user_artist_set):\n",
    "    from random import randint\n",
    "    artists_id_len = len(bAllArtistIds.value)\n",
    "#     print(artists_id_len)\n",
    "    rand_artist_ids = [bAllArtistIds.value[x] for x in [randint(0, artists_id_len - 1) for x in range(user_artist_set[2])]]\n",
    "#     print(rand_artist_ids)\n",
    "#     print(len(rand_artist_ids), user_artist_set[2])\n",
    "    return [(user_artist_set[0], x) for x in rand_artist_ids if x not in user_artist_set[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1000025, 10239908), (1000025, 1110511), (1000025, 10276798), (1000025, 2280205), (1000025, 10350940), (1000025, 10480773), (1000025, 10540439), (1000025, 1323147), (1000025, 2147128), (1000025, 10021921), (1000025, 1049907), (1000025, 6660806), (1000025, 2138468), (1000025, 1344335), (1000025, 10193716), (1000025, 10628593), (1000025, 6969532), (1000025, 6703063), (1000025, 1251888), (1000025, 10352638)]\n"
     ]
    }
   ],
   "source": [
    "# verify negativePairs\n",
    "print(negativePairs((1000025, {4609, 1000161, 1001412, 1000263, 1001735, 1001623, 1000024, 1262, 176, 1200, 688, 1001201, 4468, 1001363, 1023028, 1018807, 1000952, 1000123, 3292, 1000863}, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1014, 10752705), (1014, 10467083)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the flatmap\n",
    "negativeData.flatMap(lambda x: negativePairs(x)).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|   user|  artist|\n",
      "+-------+--------+\n",
      "|   1014|10373293|\n",
      "|   1014|10027246|\n",
      "|   1014|10567685|\n",
      "|   1014| 6927271|\n",
      "|   1014|10276537|\n",
      "|   1014|10588881|\n",
      "|   1014| 1331866|\n",
      "|   1014| 2165753|\n",
      "|   1014| 6630858|\n",
      "|   1014| 2074775|\n",
      "|   1014|10647418|\n",
      "|   1014|10553401|\n",
      "|   1014| 1254390|\n",
      "|   1014| 9901969|\n",
      "|   1014| 7002263|\n",
      "|   1014|10156020|\n",
      "|   1014| 6964306|\n",
      "|1000025|10158319|\n",
      "|1000025| 2053131|\n",
      "|1000025|10391592|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# negativeDF here will create user, artist pairs for artists that users have not listened to\n",
    "# the number will be as many as the number a user would have listened to \n",
    "negativeDF =negativeData.flatMap(lambda x: negativePairs(x)).toDF(['user', 'artist'])\n",
    "negativeDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2430828"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size \n",
    "negativeDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+\n",
      "|   user|artist|negativePrediction|\n",
      "+-------+------+------------------+\n",
      "|2105184|    13|        0.08011725|\n",
      "|2131841|    13|        0.38101718|\n",
      "+-------+------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the model to find predictions for users for artists that they have not listened to\n",
    "negativePredictions =  model.transform(negativeDF).selectExpr('user', 'artist', 'prediction as negativePrediction')\n",
    "negativePredictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join positive and negative predictions\n",
    "joinedPredictions = positivePredictions.join(negativePredictions, \"user\"). \\\n",
    "select(\"user\", \"positivePrediction\", \"negativePrediction\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total count for each pair\n",
    "allCounts = joinedPredictions. \\\n",
    "groupBy(\"user\").agg(count(lit(\"1\")).alias(\"total\")). \\\n",
    "select(\"user\", \"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider those instances where positive prediction is greater than negative prediction\n",
    "# to be correct and find their count\n",
    "correctCounts = joinedPredictions. \\\n",
    "filter(\"positivePrediction > negativePrediction\"). \\\n",
    "groupBy(\"user\").agg(count(\"user\").alias(\"correct\")). \\\n",
    "select(\"user\", \"correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|user|correct|\n",
      "+----+-------+\n",
      "| 384|    132|\n",
      "| 727|   1026|\n",
      "| 801|      1|\n",
      "|1197|    608|\n",
      "|1298|    399|\n",
      "+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a look at correct counts\n",
    "correctCounts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(auc)|\n",
      "+------------------+\n",
      "|0.9128160130138483|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take correct / total as auc and the mean as the mean auc\n",
    "meanAUC = allCounts.join(correctCounts, \"user\").\\\n",
    "selectExpr(\"user\", \"correct / total as auc\"). \\\n",
    "agg(mean(\"auc\"))\n",
    "meanAUC.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the steps executed above into a method that can use the model and the dataframe\n",
    "# to give us the mean area under the curve\n",
    "def areaUnderCurve(positiveData, bAllArtistIds, predictFunction):\n",
    "    \n",
    "    positivePredictions = predictFunction(positiveData).selectExpr('user', 'artist', 'prediction as positivePrediction')\n",
    "    \n",
    "    negativeData = positiveData.select('user', 'artist').rdd.map(lambda x: (x[0],x[1])).groupByKey() \\\n",
    "    .map(lambda x: (x[0], set(x[1]))).map(lambda x: (x[0], x[1], len(x[1])))\n",
    "    \n",
    "    def negativePairs(user_artist_set):\n",
    "        from random import randint\n",
    "        artists_id_len = len(bAllArtistIds.value)\n",
    "    #     print(artists_id_len)\n",
    "        rand_artist_ids = [bAllArtistIds.value[x] for x in [randint(0, artists_id_len - 1) for x in range(user_artist_set[2])]]\n",
    "    #     print(rand_artist_ids)\n",
    "    #     print(len(rand_artist_ids), user_artist_set[2])\n",
    "        return [(user_artist_set[0], x) for x in rand_artist_ids if x not in user_artist_set[1]]\n",
    "    \n",
    "    negativeDF =negativeData.flatMap(lambda x: negativePairs(x)).toDF(['user', 'artist'])\n",
    "\n",
    "    negativePredictions =  predictFunction(negativeDF).selectExpr('user', 'artist', 'prediction as negativePrediction')\n",
    "    \n",
    "    joinedPredictions = positivePredictions.join(negativePredictions, \"user\"). \\\n",
    "    select(\"user\", \"positivePrediction\", \"negativePrediction\").cache()\n",
    "    \n",
    "    allCounts = joinedPredictions. \\\n",
    "    groupBy(\"user\").agg(count(lit(\"1\")).alias(\"total\")). \\\n",
    "    select(\"user\", \"total\")\n",
    "\n",
    "    correctCounts = joinedPredictions. \\\n",
    "    filter(\"positivePrediction > negativePrediction\"). \\\n",
    "    groupBy(\"user\").agg(count(\"user\").alias(\"correct\")). \\\n",
    "    select(\"user\", \"correct\")\n",
    "    \n",
    "    meanAUC = allCounts.join(correctCounts, \"user\").\\\n",
    "    selectExpr(\"user\", \"correct / total as auc\"). \\\n",
    "    agg(mean(\"auc\"))\n",
    "    \n",
    "    return meanAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9128160130138483]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areaUnderCurve(cvData, bAllArtistIds, model.transform).rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33min 36s\n"
     ]
    }
   ],
   "source": [
    "# check for different parameters\n",
    "%%time\n",
    "evaluations = []\n",
    "for rank in [5, 30]:\n",
    "    for regParam in [1.0, 0.0001]:\n",
    "        for alpha in [1.0, 40.0]:\n",
    "            model = ALS(). \\\n",
    "            setSeed(100). \\\n",
    "            setImplicitPrefs(True). \\\n",
    "            setRank(rank). \\\n",
    "            setRegParam(regParam). \\\n",
    "            setAlpha(alpha). \\\n",
    "            setMaxIter(20). \\\n",
    "            setUserCol('user'). \\\n",
    "            setItemCol('artist'). \\\n",
    "            setRatingCol('count'). \\\n",
    "            setPredictionCol('prediction'). \\\n",
    "            fit(trainData)\n",
    "            \n",
    "            auc = areaUnderCurve(cvData, bAllArtistIds, model.transform).rdd.map(lambda x: x[0]).collect()\n",
    "            evaluations.append((auc, (rank, regParam, alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0.9147383340039935], (5, 1.0, 1.0)), ([0.9193732991073478], (5, 1.0, 40.0)), ([0.9118592887481435], (5, 0.0001, 1.0)), ([0.9184728075556955], (5, 0.0001, 40.0)), ([0.9138315379278659], (30, 1.0, 1.0)), ([0.9215144700377967], (30, 1.0, 40.0)), ([0.9065773223271238], (30, 0.0001, 1.0)), ([0.9210712227337515], (30, 0.0001, 40.0))]\n"
     ]
    }
   ],
   "source": [
    "print(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0.9215144700377967], (30, 1.0, 40.0)),\n",
       " ([0.9210712227337515], (30, 0.0001, 40.0)),\n",
       " ([0.9193732991073478], (5, 1.0, 40.0)),\n",
       " ([0.9184728075556955], (5, 0.0001, 40.0)),\n",
       " ([0.9147383340039935], (5, 1.0, 1.0)),\n",
       " ([0.9138315379278659], (30, 1.0, 1.0)),\n",
       " ([0.9118592887481435], (5, 0.0001, 1.0)),\n",
       " ([0.9065773223271238], (30, 0.0001, 1.0))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(evaluations, key = lambda x: -x[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
