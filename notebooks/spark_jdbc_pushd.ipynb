{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['SPARK_HOME']='/usr/lib/spark'\n",
    "os.environ['PYLIB']=os.environ['SPARK_HOME']+'/python/lib'\n",
    "sys.path.insert(0,os.environ['PYLIB']+'/py4j-0.10.7-src.zip')\n",
    "sys.path.insert(1,os.environ['PYLIB']+'/pyspark.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SparkJDBC') \\\n",
    ".config('spark.warehouse.dir','/user/hive/warehouse') \\\n",
    ".config('spark.driver.extraClassPath', \n",
    "        '/usr/share/java/mysql-connector-java.jar') \\\n",
    ".config('spark.executor.extraClassPath', \n",
    "        '/usr/share/java/mysql-connector-java.jar') \\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having set the driver and driver options we should have spark representing spark session \n",
    "# available straight away\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---+\n",
      "|   fname|   lname|age|\n",
      "+--------+--------+---+\n",
      "|    anil|  kapoor| 54|\n",
      "|  sanjay|    dutt| 56|\n",
      "|   arjun|  kappor| 28|\n",
      "|  ranbir|  kappor| 31|\n",
      "|  deepka|padukone| 29|\n",
      "|shahrukh|    khan| 51|\n",
      "| hrithik|  roshan| 37|\n",
      "+--------+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prop = {'user': 'root', 'password': 'abcd', 'driver': 'com.mysql.jdbc.Driver'}\n",
    "url = 'jdbc:mysql://localhost:3306/testdb'\n",
    "mrdf = spark.read.format('jdbc').option('url', url).option('dbtable', 'simptable') \\\n",
    ".option('user', 'root').option('password', 'abcd') \\\n",
    ".option('driver', 'com.mysql.jdbc.Driver').load()\n",
    "mrdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mrdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrdf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   lname|count|\n",
      "+--------+-----+\n",
      "|padukone|    1|\n",
      "|  roshan|    1|\n",
      "|  kappor|    2|\n",
      "|    khan|    1|\n",
      "|  kapoor|    1|\n",
      "|    dutt|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mrdf.groupBy('lname').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---+\n",
      "|   fname|   lname|age|\n",
      "+--------+--------+---+\n",
      "|   arjun|  kappor| 28|\n",
      "|  deepka|padukone| 29|\n",
      "|  ranbir|  kappor| 31|\n",
      "| hrithik|  roshan| 37|\n",
      "|    anil|  kapoor| 54|\n",
      "|  sanjay|    dutt| 56|\n",
      "|shahrukh|    khan| 51|\n",
      "+--------+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mrdf_age_lim = spark.read.format('jdbc').option('url', url).option('dbtable', 'simptable') \\\n",
    ".option('user', 'root').option('password', 'abcd') \\\n",
    ".option('driver', 'com.mysql.jdbc.Driver') \\\n",
    ".option('partitionColumn', 'age').option('lowerBound', 0).option('upperBound', 60) \\\n",
    ".option('numPartitions', 4).load()\n",
    "mrdf_age_lim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrdf_age_lim.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|  fname| lname|\n",
      "+-------+------+\n",
      "| ranbir|kappor|\n",
      "|hrithik|roshan|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actor_query = \"(select fname, lname from simptable where age between  30 and 50) pdtbl\"\n",
    "push_down_df = spark.read.jdbc(url=url, table=actor_query, properties=prop)\n",
    "push_down_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Scan JDBCRelation((select fname, lname from simptable where age between  30 and 50) pdtbl) [numPartitions=1] [fname#108,lname#109] PushedFilters: [], ReadSchema: struct<fname:string,lname:string>\n"
     ]
    }
   ],
   "source": [
    "push_down_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pushdown = spark.read.jdbc(table=\"simptable\", url=url, properties=prop).where('age between 30 and 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Scan JDBCRelation(simptable) [numPartitions=1] [fname#63,lname#64,age#65] PushedFilters: [*IsNotNull(age), *GreaterThanOrEqual(age,30), *LessThanOrEqual(age,50)], ReadSchema: struct<fname:string,lname:string,age:int>\n"
     ]
    }
   ],
   "source": [
    "df_pushdown.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+\n",
      "|  fname| lname|age|\n",
      "+-------+------+---+\n",
      "| ranbir|kappor| 31|\n",
      "|hrithik|roshan| 37|\n",
      "+-------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pushdown.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format('jdbc').option('url', url).option('dbtable', 'nstable') \\\n",
    ".option('user', 'root').option('password', 'cloudera') \\\n",
    ".option('driver', 'com.mysql.jdbc.Driver').load().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrdf.write.jdbc(url=url, mode='append', table='nstable', properties=prop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
