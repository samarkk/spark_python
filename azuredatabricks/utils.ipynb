{"cells":[{"cell_type":"code","source":["dbutils.fs.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff520748-2e7d-49db-8b8c-5303cf8fdab4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /><h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><br /></div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /><h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><br /></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.help('ls')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b6cb7d5-c98b-4741-bdc7-e5eaac8008a9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class = \"ansiout\">/**<br /> * Lists the contents of a directory.<br /> * <br /> * Example: display(ls(\"/mnt/my-folder/\"))<br /> * <br /> * The FileInfo object that is returned has the following helper methods:<br /> * val files = ls(\"/mnt/my-folder/\")<br /> * files.map(_.name)    // [myFile, myDir/]<br /> * files.map(_.length)  // [1286, 0]<br /> * files.map(_.path)    // [/mnt/my-folder/myFile, /mnt/my-folder/myDir/]<br /> * files.map(_.isDir)   // [false, true]<br /> * files.map(_.isFile)  // [true, false]<br /> * <br /> * @param dir FileSystem URI<br /> * @return Ordered sequence of FileInfos containing the name and size of each file.<br /> */<br /><b>ls(dir: java.lang.String): scala.collection.Seq</b></div><br />","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div class = \"ansiout\">/**<br /> * Lists the contents of a directory.<br /> * <br /> * Example: display(ls(\"/mnt/my-folder/\"))<br /> * <br /> * The FileInfo object that is returned has the following helper methods:<br /> * val files = ls(\"/mnt/my-folder/\")<br /> * files.map(_.name)    // [myFile, myDir/]<br /> * files.map(_.length)  // [1286, 0]<br /> * files.map(_.path)    // [/mnt/my-folder/myFile, /mnt/my-folder/myDir/]<br /> * files.map(_.isDir)   // [false, true]<br /> * files.map(_.isFile)  // [true, false]<br /> * <br /> * @param dir FileSystem URI<br /> * @return Ordered sequence of FileInfos containing the name and size of each file.<br /> */<br /><b>ls(dir: java.lang.String): scala.collection.Seq</b></div><br />"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.ls('/')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ea2fa4e-9b08-4905-b753-0d64e0043280"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: [FileInfo(path=&#39;dbfs:/FileStore/&#39;, name=&#39;FileStore/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/databricks-datasets/&#39;, name=&#39;databricks-datasets/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/databricks-results/&#39;, name=&#39;databricks-results/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/user/&#39;, name=&#39;user/&#39;, size=0)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: [FileInfo(path=&#39;dbfs:/FileStore/&#39;, name=&#39;FileStore/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/databricks-datasets/&#39;, name=&#39;databricks-datasets/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/databricks-results/&#39;, name=&#39;databricks-results/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/user/&#39;, name=&#39;user/&#39;, size=0)]</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.ls('dbfs:/FileStore')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d749522c-8ddd-40de-9a22-d7e72342a00b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: [FileInfo(path=&#39;dbfs:/FileStore/tables/&#39;, name=&#39;tables/&#39;, size=0)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [FileInfo(path=&#39;dbfs:/FileStore/tables/&#39;, name=&#39;tables/&#39;, size=0)]</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%fs ls '/dbfs/FileStore'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dde76b6f-3172-4df6-80bb-c59c5f5edd0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\">\tat shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem.listStatus(NativeAzureFileSystem.java:2468)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$2(DatabricksFileSystemV2.scala:95)\n\tat com.databricks.s3a.S3AExceptionUtils$.convertAWSExceptionToJavaIOException(DatabricksStreamUtils.scala:66)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$1(DatabricksFileSystemV2.scala:92)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:395)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:484)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:504)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionContext(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionTags(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:479)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:404)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperationWithResultTags(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:395)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:367)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperation(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.listStatus(DatabricksFileSystemV2.scala:92)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:150)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.$anonfun$ls$1(DBUtilsCore.scala:154)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.withFsSafetyCheck(DBUtilsCore.scala:91)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.ls(DBUtilsCore.scala:153)\n\tat com.databricks.dbutils_v1.impl.DbfsUtilsImpl.ls(DbfsUtilsImpl.scala:63)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:1)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:43)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:45)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:47)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw.&lt;init&gt;(command-1789190482927167:49)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw.&lt;init&gt;(command-1789190482927167:51)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read.&lt;init&gt;(command-1789190482927167:53)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$.&lt;init&gt;(command-1789190482927167:57)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$.&lt;clinit&gt;(command-1789190482927167)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$eval$.$print(&lt;notebook&gt;:6)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)\n\tat scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:219)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.$anonfun$repl$1(ScalaDriverLocal.scala:235)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:902)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:855)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:235)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$13(DriverLocal.scala:541)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:518)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)</div>","errorSummary":"FileNotFoundException: File /5185026201854937/dbfs/FileStore does not exist.","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\tat shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem.listStatus(NativeAzureFileSystem.java:2468)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$2(DatabricksFileSystemV2.scala:95)\n\tat com.databricks.s3a.S3AExceptionUtils$.convertAWSExceptionToJavaIOException(DatabricksStreamUtils.scala:66)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$1(DatabricksFileSystemV2.scala:92)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:395)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:484)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:504)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionContext(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionTags(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:479)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:404)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperationWithResultTags(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:395)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:367)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperation(DatabricksFileSystemV2.scala:510)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.listStatus(DatabricksFileSystemV2.scala:92)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:150)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.$anonfun$ls$1(DBUtilsCore.scala:154)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.withFsSafetyCheck(DBUtilsCore.scala:91)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.ls(DBUtilsCore.scala:153)\n\tat com.databricks.dbutils_v1.impl.DbfsUtilsImpl.ls(DbfsUtilsImpl.scala:63)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:1)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:43)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:45)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw$$iw.&lt;init&gt;(command-1789190482927167:47)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw$$iw.&lt;init&gt;(command-1789190482927167:49)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$$iw.&lt;init&gt;(command-1789190482927167:51)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read.&lt;init&gt;(command-1789190482927167:53)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$.&lt;init&gt;(command-1789190482927167:57)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$read$.&lt;clinit&gt;(command-1789190482927167)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$eval$.$print(&lt;notebook&gt;:6)\n\tat $linef65ef8cb48d343258593eaa68920f41325.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)\n\tat scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:219)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.$anonfun$repl$1(ScalaDriverLocal.scala:235)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:902)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:855)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:235)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$13(DriverLocal.scala:541)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:518)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.ls('dbfs:/FileStore/tables')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b47a6a8-9c79-47ea-b53d-f44fb75a9c71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[5]: [FileInfo(path=&#39;dbfs:/FileStore/tables/cm01APR2005bhav.csv&#39;, name=&#39;cm01APR2005bhav.csv&#39;, size=58696),\n FileInfo(path=&#39;dbfs:/FileStore/tables/movies10.json&#39;, name=&#39;movies10.json&#39;, size=16223),\n FileInfo(path=&#39;dbfs:/FileStore/tables/movieslim.json&#39;, name=&#39;movieslim.json&#39;, size=2101),\n FileInfo(path=&#39;dbfs:/FileStore/tables/mydata/&#39;, name=&#39;mydata/&#39;, size=0)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: [FileInfo(path=&#39;dbfs:/FileStore/tables/cm01APR2005bhav.csv&#39;, name=&#39;cm01APR2005bhav.csv&#39;, size=58696),\n FileInfo(path=&#39;dbfs:/FileStore/tables/movies10.json&#39;, name=&#39;movies10.json&#39;, size=16223),\n FileInfo(path=&#39;dbfs:/FileStore/tables/movieslim.json&#39;, name=&#39;movieslim.json&#39;, size=2101),\n FileInfo(path=&#39;dbfs:/FileStore/tables/mydata/&#39;, name=&#39;mydata/&#39;, size=0)]</div>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1789190482927162}},"nbformat":4,"nbformat_minor":0}
